Process:

To parallelize:

library(foreach)
library(bigstatsr)

example parallelizing:

library(foreach)
nproc <- parallel::detectCores()
cl <- parallel::makeCluster(nproc)
doParallel::registerDoParallel(cl)
a <- foreach(i = 1:3, .combine = 'c') %dopar% {
  sqrt(i)
}
parallel::stopCluster(cl)

To generate documentation and NAMESPACE file:

setwd('/home/bee/Github/ORdensity/')
devtools::document() 

library(help="ORdensity")

Remove the package from the current installation using

sudo R

remove.packages('ORdensity')

install again doing

sudo R

library('devtools')
install_github('jmartinezot/ORdensity')
library('ORdensity')

installing from local source

remove.packages('ORdensity')
install.packages("/home/bee/Github/ORdensity", repos = NULL, type = "source")
library('ORdensity')

remove.packages('ORdensity')
install.packages("/home/bee/Downloads/ORdensityITZIAR.tar.gz", repos = NULL, type = "source")
library('ORdensity')

remove.packages('ORdensity')
install.packages("/home/bee/Github/ORdensityOTZETA.tar.gz", repos = NULL, type = "source")
library('ORdensity')

save(myORdensityOTZETA, file = "/home/bee/Downloads/OROTZETA.RData")
save(myORdensityITZIAR, file = "/home/bee/Downloads/ORITZIAR.RData")
load("/home/bee/Downloads/OROTZETA.RData")
load("/home/bee/Downloads/ORITZIAR.RData")

remove all variables in environment

rm(list=ls())

initialize a ORdensity object
set.seed(0)
x <- example[, 3:32]
y <- example[, 33:62]
positive <- as.matrix(x)
negative <- as.matrix(y)
set.seed(0)
randomA <- matrix(rnorm(30*100), nrow = 100)
randomB <- matrix(rnorm(30*100), nrow = 100)
myORdensity <- new("ORdensity", Exp_cond_1 = randomA, Exp_cond_2 = randomB)
genLabels <- paste("SimulatedGene", 1:nrow(positive), sep="")
# myORdensity <- new("ORdensity", positive = positive, negative = negative, genIDs = genLabels, parallel = TRUE)
myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE)
out <- myORdensity@out
#res <- as.data.frame(out$res)
#res[order(res$OR, decreasing = TRUE),]
char <- myORdensity@char
myclust <- findDEgenes(myORdensity)
result <- findDEgenes(myORdensity)
# myORdensity <- new("ORdensity", positive = randomA, negative = randomB)

randomA <- matrix(rnorm(30*100), nrow = 100)
randomB <- matrix(rnorm(30*100), nrow = 100)
myORdensity <- new("ORdensity", Exp_cond_1 = randomA, Exp_cond_2 = randomB, parallel = TRUE)

a <- read.csv('/home/bee/Github/ItziarParallelizing/WeTransfer/Datos_n20000.dat', sep=" ", header=TRUE)
x <- a[, 2:31]
y <- a[, 32:61]
positive <- as.matrix(x)
negative <- as.matrix(y)
library(pryr)
system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE))
system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE))
#mem_change(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE))
#mem_change(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE))

# Datos_n1000.dat
# Parallel = TRUE
#    user  system elapsed 
# 41.838   1.282   6.984 
# Parallel = FALSE
#   user  system elapsed 
# 24.010   0.286  24.294 

# Datos_n5000.dat
# Parallel = TRUE
#   user  system elapsed 
# 526.226  61.426  90.359 
# Parallel = FALSE
# user  system elapsed 
# 281.336  39.367 320.674  

# Datos_n5000.dat
# Parallel = TRUE
# Error in unserialize(socklist[[n]]) : error reading from connection
# Timing stopped at: 10.55 10.12 209.9
# Timing stopped at: 12.31 10.22 211.8
# Parallel = FALSE
#   user   system  elapsed 
# 1145.647  186.958 1365.547 

# Datos_n10000.dat
# Parallel = TRUE
#  
# 
# Parallel = FALSE
#    user   system  elapsed 
# 1013.972  152.305 1166.241 

getOR <- function(distObject)
{	
  distMatrix <- as.matrix(distObject)
  vgR <- median(distMatrix^2)/2
  I <- apply(distMatrix, 1,  IindexRobust, vg=vgR)
  OR <- 1/I
  return(OR)
}

getOR2 <- function(distMatrix)
{	
  vgR <- med(distMatrix^2)/2
  I <- apply(distMatrix, 1,  IindexRobust2, vg=vgR)
  OR <- 1/I
  return(OR)
}

IindexRobust <- function(di, vg){
# Depth RObust index of i in C: IRobust(i) = [1 + proxiRobust(i,C)/2VRobust(C)]^{-1}
# Input:
#      di: distances from individual i to the rest 
#      vg: half geometric variability of C, estimated by means of medians
# Output:
#       index: IRobust(i)
#--------------------------------------------------------------------
  
  # di <- di[di > 0]
#   phi2 <- median(di)^2 - vg  #median(di^2) - vg  #median(di)^2 - vg  Estas dos cosas no tienen porque coincidir para n par!!!
   I <- vg/median(di)^2
   I <- as.numeric(I)

   return(I)
   
 }

IindexRobust2 <- function(di, vg){
# Depth RObust index of i in C: IRobust(i) = [1 + proxiRobust(i,C)/2VRobust(C)]^{-1}
# Input:
#      di: distances from individual i to the rest 
#      vg: half geometric variability of C, estimated by means of medians
# Output:
#       index: IRobust(i)
#--------------------------------------------------------------------
  
  # di <- di[di > 0]
#   phi2 <- median(di)^2 - vg  #median(di^2) - vg  #median(di)^2 - vg  Estas dos cosas no tienen porque coincidir para n par!!!
   I <- vg/med(di)^2
   I <- as.numeric(I)

   return(I)
   
 }

> str(globalquantilesDifferencesWeighted.null)
 num [1:5000, 1:3, 1:100] 0.0163 0.0291 -0.0217 0.0674 0.0213 ...
> format(object.size(globalquantilesDifferencesWeighted.null), unit="Mb")
[1] "11.4 Mb"
> system.time(getOR(dist(globalquantilesDifferencesWeighted.null[,,2])))
   user  system elapsed 
  2.329   0.176   2.505 
> system.time(getOR2(rdist(globalquantilesDifferencesWeighted.null[,,2])))
   user  system elapsed 
  0.830   0.112   0.942 
> system.time(distObject <- dist(globalquantilesDifferencesWeighted.null[,,2]))
   user  system elapsed 
   0.06    0.00    0.06 
> system.time(distMatrix <- as.matrix(distObject))
   user  system elapsed 
  0.704   0.076   0.780 
> format(object.size(distObject), unit="Mb")
[1] "95.4 Mb"
> format(object.size(distMatrix), unit="Mb")
[1] "191.3 Mb"
> system.time(vgR <- median(distMatrix^2)/2)
   user  system elapsed 
  0.495   0.032   0.527 
> system.time(vgR <- med(distMatrix^2)/2)
   user  system elapsed 
  0.217   0.052   0.269 
> system.time(vgR <- med(distObject^2)/2)
   user  system elapsed 
  0.076   0.000   0.077 
> system.time(I <- apply(distMatrix, 1,  IindexRobust, vg=vgR))
   user  system elapsed 
   0.92    0.00    0.92 
system.time(I <- apply(distMatrix, 1,  IindexRobust2, vg=vgR))
   user  system elapsed 
  0.613   0.000   0.615 
> system.time(OR <- 1/I)
   user  system elapsed 
      0       0       0 
> format(object.size(vgR), unit="Mb")
[1] "0 Mb"
> format(object.size(I), unit="Mb")
[1] "0.3 Mb"
> format(object.size(OR), unit="Mb")
[1] "0.3 Mb"

> str(globalquantilesDifferencesWeighted.null)
 num [1:20000, 1:3, 1:20] 0.00755 -0.09974 -0.17559 -0.16039 -0.05802 ...
> format(object.size(globalquantilesDifferencesWeighted.null), unit="Mb")
[1] "9.2 Mb"
> system.time(getOR(dist(globalquantilesDifferencesWeighted.null[,,2])))
   user  system elapsed 
 38.681   7.516  53.368
> system.time(getOR2(rdist(globalquantilesDifferencesWeighted.null[,,2])))
   user  system elapsed 
 18.972   4.883  38.502 
> system.time(distObject <- dist(globalquantilesDifferencesWeighted.null[,,2]))
   user  system elapsed 
  0.976   0.000   0.979 
> system.time(distMatrix <- as.matrix(distObject))
   user  system elapsed 
 13.056   3.259  17.300 
> format(object.size(distObject), unit="Mb")
[1] "1525.8 Mb"
> format(object.size(distMatrix), unit="Mb")
[1] "3054.2 Mb"
> system.time(vgR <- median(distMatrix^2)/2)
   user  system elapsed 
  6.283   2.334  10.009 
> system.time(vgR <- med(distMatrix^2)/2)
   user  system elapsed 
  4.853   1.150   6.038 
> system.time(vgR <- med(distObject^2)/2)
   user  system elapsed 
  1.742   0.576   2.321 
> system.time(I <- apply(distMatrix, 1,  IindexRobust, vg=vgR))
   user  system elapsed 
 18.467   3.504  35.719 
> system.time(I <- apply(distMatrix, 1,  IindexRobust2, vg=vgR))
   user  system elapsed 
 12.595   1.074  13.682 
> system.time(OR <- 1/I)
   user  system elapsed 
      0       0       0 
> format(object.size(vgR), unit="Mb")
[1] "0 Mb"
> format(object.size(I), unit="Mb")
[1] "1.4 Mb"
> format(object.size(OR), unit="Mb")
[1] "1.4 Mb"



system.time(getOR2(rdist(globalquantilesDifferencesWeighted.null[,,2])))

positiveCases <- positive
negativeCases <- negative

summaries(myORdensity)
plotFPvsOR(myORdensity)
plotclusters(myORdensity)
clusplotk(myORdensity, 2)
clusplotk(myORdensity, 4)

let us see what it contains
myORdensity@positive
myORdensity@negative
myORdensity@.out # this has to be empty

initialize the .out field
myORdensity <- compute.ORdensity(myORdensity)
out <- myORdensity@.out

out$summary
OR <- out$summary[, "OR"]
FP <- out$summary[, "mediaFP"] # Aldatu izena
dFP <- out$summary[, "density"]
plot(FP, OR, type="n")
points(FP, OR, cex=1/(0.5+dFP))

library(cluster)
char <- data.frame(OR, FP, dFP)
s <- rep(NA, 10)
for (k in 2:10)
{
  aux <- pam(dist(scale(char)), k)
  s[k] <- mean(silhouette(aux)[, "sil_width"])
}
plot(s, type="b", ylim=c(0,1))

# Try 2, 3, and 4 clusters
k <- 4
clustering <- pam(dist(scale(char)), k)$clustering
by(char, clustering, summary)

veryimportant <- out$summary[clustering==1, "id"]
table(dat$DEgen[veryimportant])
table( dat$gap[veryimportant])
important <- out$summary[clustering==2, "id"]
table(dat$DEgen[important])
table( dat$gap[important])
doubtfull <- out$summary[clustering==3, "id"]
table(dat$DEgen[doubtfull])
table( dat$gap[doubtfull])
nonimportant <- out$summary[clustering==4, "id"]
table(dat$DEgen[nonimportant])

clustering <- pam(dist(scale(char)), 2)$clustering
veryimportant <- out$summary[clustering==1, "id"]
table(dat$DEgen[veryimportant])
table( dat$gap[veryimportant])
nonimportant <- out$summary[clustering==2, "id"]
table(dat$DEgen[nonimportant])


aa <- pam(dist(scale(char)), 2)
clusplot(aa)
aa <- pam(dist(scale(char)), 4)
ama <- clusplot(aa)
aux <- prcomp(char, scale=TRUE)
x <- aux$x[, 1:2]
getAnywhere(clusplot.default)

library(foreach)
nproc <- parallel::detectCores()
cl <- parallel::makeCluster(nproc)
doParallel::registerDoParallel(cl)
a <- foreach(i = 1:3, .combine = 'c') %dopar% {
  # sqrt(i)
  l <- list()
  m <- matrix(1:50, nrow=10)
  l[[1]] <- m
  l[[2]] <- 14
  l
}
parallel::stopCluster(cl)


check_complexity <- function(n) {
	m <<- matrix(runif(n*3, min = -2, max = 2), nrow=n)
	print(system.time(D0 <<- as.matrix(dist(m))))
	print(system.time(vgR0 <<- median(D0^2)/2))
	print(system.time(I <<- apply(D0, 1,  IindexRobust, vg=vgR0)))
	print(system.time(1/I))
}

format(object.size(D0), units = "GB", standard = "SI")

> check_complexity(10000)
   user  system elapsed 
  4.821   0.850   5.670 
   user  system elapsed 
  2.523   0.471   2.994 
   user  system elapsed 
  5.146   0.218   5.363 
   user  system elapsed 
  0.000   0.000   0.001 
> format(object.size(D0), units = "MB", standard = "SI")
[1] "801.1 MB"
> check_complexity(20000)
   user  system elapsed 
 22.440  10.824 938.224 
   user  system elapsed 
 11.102   3.018 128.688 
    user   system  elapsed 
  24.326   20.705 1740.560 
   user  system elapsed 
      0       0       0 
> format(object.size(D0), units = "MB", standard = "SI")
[1] "3202.2 MB"

library(gpuR)

check_complexity_GPU <- function(n) {
	m <<- matrix(runif(n*3, min = -2, max = 2), nrow=n)
	gpum <<- gpuMatrix(m, type="double")
	print(system.time(D0 <<- as.matrix(dist(gpum))))
	print(system.time(vgR0 <<- median(D0^2)/2))
	# print(system.time(I <<- apply(D0, 1,  IindexRobust, vg=vgR0)))
	# print(system.time(1/I))
}

veryimportant <- out$summary[clustering==1, "id"]
table(dat$DEgen[veryimportant])
table( dat$gap[veryimportant])
important <- out$summary[clustering==2, "id"]
table(dat$DEgen[important])
table( dat$gap[important])
doubtfull <- out$summary[clustering==3, "id"]
table(dat$DEgen[doubtfull])
table( dat$gap[doubtfull])
nonimportant <- out$summary[clustering==4, "id"]
table(dat$DEgen[nonimportant])

clustering <- pam(dist(scale(char)), 2)$clustering
veryimportant <- out$summary[clustering==1, "id"]
table(dat$DEgen[veryimportant])
table( dat$gap[veryimportant])
nonimportant <- out$summary[clustering==2, "id"]
table(dat$DEgen[nonimportant])


out <- myORdensity@out
clustering2 <- myORdensity@clustering2
veryimportant <- out$summary[clustering2==1, "id"]
table(example$DEgen[veryimportant])
table(example$gap[veryimportant])
nonimportant <- out$summary[clustering2==2, "id"]
table(example$DEgen[nonimportant])
table(example$gap[nonimportant])

clustering4 <- myORdensity@clustering4
veryimportant <- out$summary[clustering4==1, "id"]
table(example$DEgen[veryimportant])
table(example$gap[veryimportant])
important <- out$summary[clustering4==2, "id"]
table(example$DEgen[important])
table(example$gap[important])
doubtful <- out$summary[clustering4==3, "id"]
table(example$DEgen[doubtful])
table(example$gap[doubtful])
nonimportant <- out$summary[clustering4==4, "id"]
table(example$DEgen[nonimportant])
table(example$gap[nonimportant])


data <- "/home/bee/Github/ItziarParallelizing/WeTransfer/Datos_n1000.dat"
> fast <- FALSE
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
   user  system elapsed 
 55.458   1.396  56.846 
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE, verbose = FALSE))
   user  system elapsed 
 46.983   1.873   8.260 
> fast <- TRUE
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
   user  system elapsed 
 50.104   0.016  50.114 
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE, verbose = FALSE))
   user  system elapsed 
 41.027   1.752   7.385 

> data <- "/home/bee/Github/ItziarParallelizing/WeTransfer/Datos_n5000.dat"
> fast <- FALSE
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
   user  system elapsed 
355.784  48.114 403.873 
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE, verbose = FALSE))
   user  system elapsed 
561.378  54.787  95.848 
> fast <- TRUE
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
   user  system elapsed 
222.379  19.400 241.791 
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = TRUE, verbose = FALSE))
   user  system elapsed 
462.288  53.394  81.575 

> data <- "/home/bee/Github/ItziarParallelizing/WeTransfer/Datos_n20000.dat"
> fast <- TRUE
> cat("fast variable is set to:", fast, "\n")
fast variable is set to: TRUE 
> cat("Not parallel:\n")
Not parallel:
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
    user   system  elapsed 
2133.147  344.748 2478.593 

> data <- "/home/bee/Github/ItziarParallelizing/WeTransfer/Datos_n50000.dat"
> fast <- TRUE
> cat("fast variable is set to:", fast, "\n")
fast variable is set to: TRUE 
> cat("Not parallel:\n")
Not parallel:
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
Error: cannot allocate vector of size 18.6 Gb
Timing stopped at: 0.206 0 0.206
Timing stopped at: 7.065 0.008 7.071
Timing stopped at: 7.171 0.032 7.202
Timing stopped at: 21.23 1.642 22.87

a <- read.csv(data, sep=" ", header=TRUE)
x <- a[, 2:31]
y <- a[, 32:61]
positive <- as.matrix(x)
negative <- as.matrix(y)

median_estimator <- function(previous_estimator, number_previous_cases, v)
{
current_estimator <- previous_estimator
number_previous_cases <- number_previous_cases
cumadev <- 0
n <- length(v)
for (i in 1:n)
{
number_previous_cases <- number_previous_cases + 1
cumadev <- cumadev + abs(v[i] - current_estimator)
eta = 1.5 * cumadev/(number_previous_cases * number_previous_cases)
current_estimator <- current_estimator + eta * sign(v[i] - current_estimator)
}
return (current_estimator)
}


> set.seed(0)
> ncases <- 50000
> rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
> system.time({d1 <- dist(rvalues)})
   user  system elapsed 
  6.727   1.584   8.310 
> system.time({d2 <- rdist(rvalues)})
Error: cannot allocate vector of size 18.6 Gb
Timing stopped at: 0.14 0 0.139
> system.time({d3 <- distances(rvalues)})
   user  system elapsed 
  0.063   0.003   0.082 
> format(object.size(d1), unit="Mb")
[1] "9536.6 Mb"
> format(object.size(d3), unit="Mb")
[1] "1.1 Mb"
> d3
Error: cannot allocate vector of size 18.6 Gb
In addition: Warning message:
In print.distances(x) :
  `x` contains too many data points, showing the first 20 out of the total 50000.

> set.seed(0)
> ncases <- 20000
> rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
> system.time({d1 <- dist(rvalues)})
   user  system elapsed 
  1.036   0.293   1.330 
> system.time({d2 <- rdist(rvalues)})
   user  system elapsed 
  2.636   0.506   3.142 
> system.time({d3 <- distances(rvalues)})
   user  system elapsed 
      0       0       0 
> format(object.size(d1), unit="Mb")
[1] "1525.8 Mb"
> format(object.size(d2), unit="Mb")
[1] "3051.8 Mb"
> format(object.size(d3), unit="Mb")
[1] "0.5 Mb"

set.seed(0)
ncases <- 20000
rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
system.time(Rfast::med(as.matrix(distances::distances(rvalues))))
   user  system elapsed 
 16.276   4.073  20.384  
system.time(Rfast::med(distances::distances(rvalues)[1:20000, 1:20000]))
   user  system elapsed 
  4.867   1.147   6.015 
system.time({d <- distances::distances(rvalues)
Rfast::med(d[1:(dim(d)[2]), 1:(dim(d)[2])])})
   user  system elapsed 
  4.861   1.132   5.994  

median_of_medians_of_distances <- function(m)
{
   d <- distances(m)
   med_columns <- rep(100,nrow(m))
   for (i in 1:nrow(m)) 
   {
       med_columns[i] <- med(distance_columns(d,i))
   }
   return (med(med_columns))
}

system.time({median_of_medians_of_distances(rvalues)})

set.seed(0)
ncases <- 100000
rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
system.time({median_of_medians_of_distances(rvalues)})
    user   system  elapsed 
1377.600    2.276 1380.010

set.seed(0)
ncases <- 50000
rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
system.time({median_of_medians_of_distances(rvalues)})
   user  system elapsed 
307.930   0.524 308.424 

set.seed(0)
ncases <- 75000
rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
system.time({median_of_medians_of_distances(rvalues)})
   user  system elapsed 
871.952   1.704 874.584

all_distances <- function(m)
{
   n_cases <- nrow(m)
   for (i in 1:(n_cases-1))
   {
      for (j in (i+1):n_cases)
      {
         d <- sum((m[i,] - m[j,])^2)
      }
   }
}


set.seed(0)
ncases <- 10000
rvalues <- matrix(rnorm(ncases * 3), ncol = 3)




> set.seed(0)
> ncases <- 50000
> rvalues <- matrix(rnorm(ncases * 3), ncol = 3)
> system.time(all_distances(rvalues))
    user   system  elapsed 
1113.337    0.096 1113.342 

m <- matrix(c(72, 37, 28, 63), nrow = 2)

accuracy <- function(m)
{
total <- sum(m)
return(sum(diag(m)) / total)
}

kappa <- function(m)
{
acc <- accuracy(m)
p_e <- 0
for (j in 1:nrow(m))
   {
	p_e <- p_e + (sum(m[j,])/ sum(m)) * (sum(m[,j])/ sum(m))
   }
return((acc - p_e) / (1-p_e))
}

sensitivity <- function(m)
{
return(m[1,1]/(m[1,1] + m[2,1]))
}

specificity <- function(m)
{
return(m[2,2]/(m[2,2] + m[1,2]))
}

precision <- function(m)
{
return(m[1,1]/(m[1,1] + m[1,2]))
}

recall <- function(m)
{
return(sensitivity(m))
}

F <- function(m)
{
return ((2*precision(m)*recall(m))/ (recall(m) + precision(m)) )
}

format(object.size(1.0) * 20000 * 20000, unit="auto")


Error in apply(originalDataFPStatistics[, 1, ], 1, function(x) { : 
  dim(X) must have a positive length
NO Cargar paquetes al principio
OK Estimación de tamaño

20000
> system.time(myORdensity <- new("ORdensity", Exp_cond_1 = positive, Exp_cond_2 = negative, parallel = FALSE, verbose = FALSE))
An object of size 3 Gb is going to be created in memory. If the parallel option is enabled, as many objects of that size as the number of processors in your computer, are going to be created at the same time. Please consider that when running this code.
A bootstrap replication takes 31.051 seconds, and you have requested 100 bootstrap replications.
    user   system  elapsed 
4707.693  246.898 5209.893 

n_genes <- 5
n_cases <- 5
positiveCases <- matrix(rnorm(n_genes * n_cases), ncol=n_cases)
negativeCases <- matrix(rnorm(n_genes * n_cases), ncol=n_cases)

n_objects <- 5
n_features <- 3
objects <- matrix(rnorm(n_objects * n_features), ncol=n_features)
d1 <- distances::distances(objects)
d2 <- fields::rdist(objects)
d3 <- dist(objects)
getOR(d1)
getOR(d1[1:(dim(d1)[2]), 1:(dim(d1)[2])])
getOR(d2)
getOR(as.matrix(d3))


> myORdensity10000 <- new("ORdensity", Exp_cond_1 = EXC.1, Exp_cond_2 = EXC.2, B = 10000)
An object of size 7.6 Mb is going to be created in memory. If the parallel option is enabled, as many objects of that size as the number of processors in your computer, are going to be created at the same time. Please consider that when running this code.
A bootstrap replication takes 0.318 seconds, and you have requested 10000 bootstrap replications.
Warning message:
In eval(formal.args[[as.character(substitute(arg))]], envir = sys.frame(sysP)) :
  restarting interrupted promise evaluation


library(testthat)
library(ORdensity)
setwd("/home/bee/Github/ORdensity/tests")
x <- simexpr[, 3:32]
y <- simexpr[, 33:62]
EXC.1 <- as.matrix(x)
EXC.2 <- as.matrix(y)
test_results <- test_dir(".", reporter="summary")
test_results





